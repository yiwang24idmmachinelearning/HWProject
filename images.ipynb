{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SIGN LANGUAGE DATASET](https://www.kaggle.com/datasets/nikhilgawai/sign-language-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/data_utils.py\n",
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/image_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up and resize images\n",
    "\n",
    "Export all as 3-channel `jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, path\n",
    "from image_utils import open_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_in_dir = \"../9103-utils/datasets/image/sign-language\"\n",
    "img_out_dir = \"./data/image/sign-language/\"\n",
    "\n",
    "in_dirs = sorted([d for d in listdir(img_in_dir) if path.isdir(path.join(img_in_dir, d))])\n",
    "\n",
    "def is_image_file(f):\n",
    "  f_lower = f.lower()\n",
    "  for e in [\"jpg\", \"jpeg\", \"png\"]:\n",
    "    if f_lower.endswith(e):\n",
    "      return True\n",
    "  return False\n",
    "\n",
    "for d in in_dirs:\n",
    "  in_path = path.join(img_in_dir, d)\n",
    "  fnames = sorted([f for f in listdir(in_path) if is_image_file(f)])\n",
    "  for i,f in enumerate(fnames):\n",
    "    img = open_image(path.join(in_path, f)).convert(\"RGB\")\n",
    "    img.thumbnail([300, 200])\n",
    "    img.save(path.join(img_out_dir, f\"{d}-{('000'+str(i))[-2:]}.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from nn_utils import SignUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = SignUtils.train_test_split_cnn(test_ratio=0.2)\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dl = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img,label = next(iter(train_dl))\n",
    "print(img.shape, label.shape)\n",
    "display(v2.ToPILImage()(img[0]))\n",
    "display(v2.ToPILImage()(img[1]))\n",
    "display(v2.ToPILImage()(img[2]))\n",
    "\n",
    "with torch.no_grad():\n",
    "  img,label = next(iter(test_dl))\n",
    "  print(img.shape, label.shape)\n",
    "  display(v2.ToPILImage()(img[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create image lists for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image path\n",
    "data_dir = \"data/image/sign-language\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "def load_images(data_dir):\n",
    "  fnames = sorted([f for f in os.listdir(data_dir) if f.endswith(\"jpg\")])\n",
    "\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  for img_name in fnames:\n",
    "    label = img_name.split(\"-\")[0]\n",
    "    # Open the image and grayscale it\n",
    "    img_path = os.path.join(data_dir, img_name)\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    img = img.resize((64, 64))  # 调整到固定大小\n",
    "    data.append(np.array(img).flatten())  # 展平图像\n",
    "    labels.append(label)\n",
    "\n",
    "  return np.array(data), np.array(labels), sorted(list(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_images returns the categories now\n",
    "X_np, y_np, categories = load_images(data_dir)\n",
    "\n",
    "# this will have encode the categories into numbers\n",
    "category2id = {c:i for i,c in enumerate(categories)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "X_np, y_np = load_images(data_dir, categories)\n",
    "X = pd.DataFrame(X_np)\n",
    "y = pd.DataFrame(y_np,columns=['label'])\n",
    "\n",
    "# Code should be the same after this point"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "9103",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
